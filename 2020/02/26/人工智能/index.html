<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="Hope_Y's blog" type="application/atom+xml">






<meta name="description" content="人工智能学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能">
<meta property="og:url" content="http://yoursite.com/2020/02/26/人工智能/index.html">
<meta property="og:site_name" content="Hope_Y&#39;s blog">
<meta property="og:description" content="人工智能学习笔记">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/images/%E6%A1%86%E6%9E%B6%E7%BB%93%E6%9E%84.jpg">
<meta property="og:image" content="http://yoursite.com/images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4.jpg">
<meta property="og:updated_time" content="2020-09-08T12:42:18.193Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="人工智能">
<meta name="twitter:description" content="人工智能学习笔记">
<meta name="twitter:image" content="http://yoursite.com/images/%E6%A1%86%E6%9E%B6%E7%BB%93%E6%9E%84.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/02/26/人工智能/">



  <script> 
   (function(){
          if(''){
              if (prompt('请输入文章密码') !== ''){
                  alert('密码错误！');
                  history.back();
              }
          }
      })();
  </script>

  <title>人工智能 | Hope_Y's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hope_Y's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/26/人工智能/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hope_Y">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/00.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hope_Y's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">人工智能</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-26T14:36:24+08:00">
                2020-02-26
              </time>
            
            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2020-09-08T20:42:18+08:00">
                2020-09-08
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/课堂笔记/" itemprop="url" rel="index">
                    <span itemprop="name">课堂笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/02/26/人工智能/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/02/26/人工智能/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>人工智能学习笔记</p>
<a id="more"></a>

<h1 id="第一讲-人工智能概述"><a href="#第一讲-人工智能概述" class="headerlink" title="第一讲 人工智能概述"></a>第一讲 人工智能概述</h1><h2 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h2><p>1956年正式提出，被誉为20世纪三大科学技术成就（空间技术、原子能技术、人工智能技术）</p>
<h2 id="1-2-人工智能的概念"><a href="#1-2-人工智能的概念" class="headerlink" title="1.2 人工智能的概念"></a>1.2 人工智能的概念</h2><p>对于智能到现在为止暂时没有一个准确的定义，只有一些主要流派。计算机人工智能暂时定义为<strong>智能是知识与智力的总和</strong>。</p>
<p>智能的特征：</p>
<p>1、感知能力（感知外部世界的能力，主要是视觉和听觉）</p>
<p>2、记忆与思维能力（存储与对于记忆信息的处理）</p>
<p>3、学习能力（分自主和无意识的学习）</p>
<p>4、行为能力（对于信息的输出）</p>
<h2 id="1-3-人工智能的发展简史"><a href="#1-3-人工智能的发展简史" class="headerlink" title="1.3 人工智能的发展简史"></a>1.3 人工智能的发展简史</h2><p>提出(-1956年)-&gt;形成(1956-1969)-&gt;发展(1970-)</p>
<h2 id="1-4-人工智能研究的基本内容不同学派"><a href="#1-4-人工智能研究的基本内容不同学派" class="headerlink" title="1.4 人工智能研究的基本内容不同学派"></a>1.4 人工智能研究的基本内容不同学派</h2><p>机器学习：监督学习、强化学习、非监督学习</p>
<ul>
<li>符号主义：主要是面向逻辑符号的研究</li>
<li>连接主义：仿生应用（神经网络）</li>
<li>行为主义：感知-行动</li>
</ul>
<ul>
<li>计算智能定义</li>
</ul>
<h1 id="第二讲-一阶谓词逻辑知识表示法"><a href="#第二讲-一阶谓词逻辑知识表示法" class="headerlink" title="第二讲 一阶谓词逻辑知识表示法"></a>第二讲 一阶谓词逻辑知识表示法</h1><h2 id="2-1-命题逻辑"><a href="#2-1-命题逻辑" class="headerlink" title="2.1 命题逻辑"></a>2.1 命题逻辑</h2><p>$$<br>逻辑<br>\begin{cases}<br>经典逻辑(二值逻辑)<br>\begin{cases}<br>经典命题逻辑<br>\newline<br>一阶谓词逻辑<br>\end{cases}<br>\newline<br>非经典逻辑<br>\begin{cases}<br>三值逻辑<br>\newline<br>多值逻辑<br>\newline<br>模糊逻辑<br>\end{cases}<br>\end{cases}<br>$$</p>
<p>命题：一个<strong>非真即假</strong>的<strong>陈述句</strong></p>
<h2 id="2-2-谓词逻辑"><a href="#2-2-谓词逻辑" class="headerlink" title="2.2 谓词逻辑"></a>2.2 谓词逻辑</h2><p> 谓词</p>
<p>一般形式：$P(X_1,X_2,…,X_N)$</p>
<p>个体$P(X_1,X_2,…,X_N)$：某个独立存在的事物或者某个抽象的概念。</p>
<p>谓词名$P$：刻画个体的性质、状态或个体间的关系。</p>
<p>个体是一个常量；一个或者一组指定的个体，一元谓词、二元谓词…</p>
<p>个体也可以是一个变量；此时真假可能不确定</p>
<p>个体还可以是函数；一个个体到另一个个体的映射</p>
<p>个体可以是谓词；二阶谓词等</p>
<p> 谓词公式</p>
<p>非($\neg $)；或($\vee$)；与($\wedge$)；蕴含，表如果…那么…($\rightarrow $)；等价($\leftrightarrow$)</p>
<p>谓词逻辑真值表<del>(或且非就不列了)</del></p>
<table>
<thead>
<tr>
<th align="center">$P$</th>
<th align="center">$Q$</th>
<th align="center">$P \rightarrow Q$ （真假即假）</th>
<th align="center">$P \leftrightarrow Q$ （相当于同或）</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$T$</td>
<td align="center">$T$</td>
<td align="center">$T$</td>
<td align="center">$T$</td>
</tr>
<tr>
<td align="center">$T$</td>
<td align="center">$F$</td>
<td align="center">$F$</td>
<td align="center">$F$</td>
</tr>
<tr>
<td align="center">$F$</td>
<td align="center">$T$</td>
<td align="center">$T$</td>
<td align="center">$F$</td>
</tr>
<tr>
<td align="center">$F$</td>
<td align="center">$F$</td>
<td align="center">$T$</td>
<td align="center">$T$</td>
</tr>
</tbody></table>
<p>全称量词$\forall$；存在量词$\exists$</p>
<p>全称量词和存在量词的次序可能会影响命题的真假性</p>
<p>连接词的优先级从高到低($\neg \ &gt;\ \wedge \ &gt;\  \vee \  &gt; \ \rightarrow \  &gt; \ \leftrightarrow $)</p>
<p>量词的辖域：位于两次后面的单个谓词或者用括弧括起来的谓词公式（一般用全称量词和存在量词表示）</p>
<p>约束变量与自由变元：辖域内的变量就是约束变元，其他就是自由变元，但是这个是相对的。</p>
<p>谓词公式的性质</p>
<p>化简式：$P \wedge Q \Rightarrow P , P \wedge Q \Rightarrow Q$</p>
<p>附加式：$P \Rightarrow P \vee Q$</p>
<p>析取三段论：$\neg P , P \vee Q \Rightarrow Q$</p>
<p>假言推理：$P, P \rightarrow Q \Rightarrow Q$</p>
<p>拒取式推理：$\neg Q , P \rightarrow Q \Rightarrow \neg P$</p>
<p>假言三段论：$A \rightarrow B , B \rightarrow C \Rightarrow A \rightarrow C$</p>
<p>构造性二难：$P \vee Q , P \rightarrow R , Q \rightarrow R \Rightarrow R $</p>
<p>全称固化：$(\forall x)P(x) \Rightarrow P(y)$</p>
<p>存在固化：$(\exists x)P(x) \Rightarrow P(x_0)$</p>
<p>反证法：正难则反</p>
<h2 id="2-3-一阶谓词逻辑知识表示法"><a href="#2-3-一阶谓词逻辑知识表示法" class="headerlink" title="2.3 一阶谓词逻辑知识表示法"></a>2.3 一阶谓词逻辑知识表示法</h2><p> 一阶谓词逻辑知识表示法</p>
<p>1、定义谓词及个体</p>
<p>2、变元赋值</p>
<p>3、用连接词连接各个谓词，形成谓词公式</p>
<p> 一阶谓词逻辑知识表示法特点</p>
<p>优点：自然性；精确性；严密性；容易实现</p>
<p>缺点：不能表示不确定的知识；组合爆炸；效率低</p>
<p>应用：自动问答系统；机器人行动规划系统；机器博弈系统；问题求解系统</p>
<h1 id="第三讲-产生式表示法和框架表示法"><a href="#第三讲-产生式表示法和框架表示法" class="headerlink" title="第三讲 产生式表示法和框架表示法"></a>第三讲 产生式表示法和框架表示法</h1><h2 id="3-1-产生式表示法"><a href="#3-1-产生式表示法" class="headerlink" title="3.1 产生式表示法"></a>3.1 产生式表示法</h2><p> IF    P    THEN   Q       或者      P→Q </p>
<p>确定性规则知识产生式表示、不确定性规则知识产生式表示（加上置信度）、确定性事实性知识的产生式表示（三元组表示）、不确定性事实性知识的产生式表示（在前面的基础上机上置信度）</p>
<p>产生式与崔此逻辑中蕴含式的区别</p>
<p>1、产生式除了能表示蕴含，还可以表示操作规则、变换、函数等</p>
<p>2、蕴含只能表达精确的知识（非真即假），而产生式还能表示“可能”</p>
<p>巴克斯范式$BNF$：定义描述，$::=$表示定义为，$|$表示或，$[]$表示可缺省</p>
<pre class="mermaid">graph TB
    A[控制] --> B[规则库]
    A --> C[推理机]
    A --> D[综合数据库]
    B --> C
    D --> C
    C --> D</pre>



<p>规则库：用于描述相应领域内知识的产生式集合。</p>
<p>综合数据库（事实库、上下文、黑板等）：一个用于存放问题求解过程中各种当前信息的数据结构。</p>
<p>控制系统（推理机构）：由一组程序组成，负责整个产生式系统的运行，实现对问题的求解。</p>
<p>产生式优点：自然性、模块性、有效性、清晰性</p>
<p>缺点：效率不高、不能表达结构性知识</p>
<p>适用场合：1、领域知识间关系不密切，不存在结构关系。2、经验性及不确定性的知识，且相关领域中对这些知识 没有严格、统一的理论。3、领域问题的求解过程可被表示为一系列相对独立的操作，且每个操作可被表示为一条或多条产生式规则。</p>
<h2 id="3-2-语义网络表示法"><a href="#3-2-语义网络表示法" class="headerlink" title="3.2 语义网络表示法"></a>3.2 语义网络表示法</h2><ul>
<li><p>语义基元</p>
<p>语义网络中最基本的语义单元称为语义基元，可用三元组表示为：</p>
<pre><code>（结点1，弧，结点2）</code></pre></li>
<li><p>基本网元<br>指一个语义基元对应的有向图，是语义网络中最基本的结构单元</p>
</li>
<li><p>实例关系： ISA</p>
</li>
<li><p>分类关系： AKO</p>
</li>
<li><p>成员关系： A-Member-of</p>
</li>
<li><p><strong>上述关系的主要特征</strong>：属性的继承性，即处在具体层的结点可以继承抽象层结点的所有属性</p>
</li>
<li><p>属性关系：Have、Can</p>
</li>
<li><p>包含关系（聚类关系）：part-of</p>
</li>
<li><p>时间关系</p>
</li>
<li><p>位置关系</p>
</li>
<li><p>相近关系</p>
<p>可以有一对一关系，也可以有一对多和多对多的关系</p>
</li>
<li><p>优点：结构性、联想性、自然性</p>
</li>
<li><p>缺点：非严格性、复杂性</p>
</li>
</ul>
<h2 id="3-3-框架表示法"><a href="#3-3-框架表示法" class="headerlink" title="3.3 框架表示法"></a>3.3 框架表示法</h2><p>框架(frame)：一种描述所论对象属性的数据结构，一个框架由若干个“槽”的结构组成，每个槽又可根据实际情况分成若干个“侧面”。</p>
<p>槽(slot)：用于描述所论对象某一方面的属性</p>
<p>侧面(faced)：描述相应属性的某一方面（细分下的细分）</p>
<p>结构：</p>
<p><img src="/images/%E6%A1%86%E6%9E%B6%E7%BB%93%E6%9E%84.jpg" alt="alt"></p>
<p>特点：结构性、继承性、自然性、便于表达结构性的知识</p>
<h1 id="第四讲-基于谓词逻辑的推理方法"><a href="#第四讲-基于谓词逻辑的推理方法" class="headerlink" title="第四讲 基于谓词逻辑的推理方法"></a>第四讲 基于谓词逻辑的推理方法</h1><ul>
<li><p>置换</p>
<ul>
<li><p>可以简单理解维在一个谓词公式中用置换项去顶替变量</p>
</li>
<li><p>形如$\{ t_1 /x_1 ,t_2/x_2,…,t_n/x_n\}$</p>
</li>
<li><p>用$t_i$代替$x_i$</p>
<ul>
<li>使得$t_i$与$x_i$不相同</li>
<li>$x_i$不能循环出现在另一个$t_j$中（例如$\{ g(z)/x , f(x)/z \}$就不是一个置换，但是$\{ g(a)/x , f(x)/z \}$是置换，因为无循环递推）</li>
</ul>
</li>
<li><p>设$\theta = \{ t_1 /x_1 ,t_2/x_2,…,t_n/x_n\}$，将$x_i$换成$t_i$得到$G$，称$G$为$F$在置换$\theta$下的<strong>例示</strong>，记作$G = F \theta$</p>
</li>
<li><p>$\theta \circ \lambda$：$\theta = \{ t_1 /x_1 ,t_2/x_2,…,t_n/x_n\} \lambda= \{ u_1 /y_1 ,u_2/y_2,…,u_m/y_m\}$ </p>
<p>得到 $\{ t_1 \lambda /x_1 ,t_2 \lambda /x_2,…,t_n \lambda /x_n ,u_1 /y_1 ,u_2/y_2,…,u_m/y_m\}$。删除两种元素，一种为$t_i \lambda  = x_i$；另一种为$y_j = x_i$</p>
<ul>
<li>其中值得注意的是$t_i \lambda$：用$\lambda$置换$t_i$，例如$f(y)/x$，$b/y$，置换成$f(b/y)/x = f(b)/x$</li>
</ul>
</li>
</ul>
</li>
<li><p>合一：设有公式集$F = \{F_1,F_1,…,F_n \}$，寻找一个置换$\theta$使得$F_1 \theta = F_2 \theta = … =F_n \theta$</p>
</li>
</ul>
<h2 id="归结演绎推理"><a href="#归结演绎推理" class="headerlink" title="归结演绎推理"></a>归结演绎推理</h2><p>反证法：$P \Rightarrow Q$，当且仅当$P \wedge \neg Q \Leftrightarrow F$，即$Q$为$P$的逻辑结论，当且仅当$P \wedge \neg Q$为假。</p>
<p><strong>谓词公式转变为子句集</strong></p>
<p>原子(atom)谓词公式：一个不能再分解的命题</p>
<p>文字：原子谓词公式及其否定</p>
<p>$P$：正文字；$\neg P$：负文字</p>
<p>子句：任何文字的析取式。任何文字本身也都是子句</p>
<p>空子句：不包含任何文字的子句，空子句是永假的</p>
<p>$A \rightarrow B$可化为$A \wedge \neg B$</p>
<p>$A \leftrightarrow B$可化为$( A \wedge B ) \vee ( \neg A \wedge \neg B )$</p>
<p>德摩根律（略）</p>
<p><strong>化为Skolem标准型</strong></p>
<p>化为前束形：前束形=(前缀){母式}，把量词约束提前</p>
<p><strong>消去存在量词</strong></p>
<p>存在量词不出现在全称量词的辖域内；存在量词出现在一个或者多个全称量词的辖域内。</p>
<p><code>Skolem化</code>：用Skolem函数代替存在变量</p>
<p>$( \forall x_1)(( \forall x_2)…( \forall x_n)( \exists y)P(x_1,x_2,…,x_n,y)))$，存在量词$y$的Skolem函数为$y=f(x_1,x_2,…,x_n)$</p>
<p>Skolem标准型（分配律）</p>
<p>$P \vee (Q \wedge R) \Leftrightarrow (P \vee Q) \wedge (P \vee R)$</p>
<p>$P \wedge (Q \vee R) \Leftrightarrow (P \wedge Q) \vee (P \wedge R)$</p>
<p>略去全称量词</p>
<p>消去合取词：将上面的母式划分为若干个子句</p>
<p>子句变量标准化（每个子句变量不同）</p>
<p>谓词公式和子句集是否等价？</p>
<p>答：谓词公式和子句集不总是等价的，在谓词公式不可满足的条件下等价。在基于谓词逻辑的推理中，特别是归结推理中，把谓词公式转化为子句集是必要的。</p>
<h2 id="鲁宾逊归结原理"><a href="#鲁宾逊归结原理" class="headerlink" title="鲁宾逊归结原理"></a>鲁宾逊归结原理</h2><p>子句集中子句之间都必须是合取关系</p>
<p>基本思想：首先检查$S$是否含空语句，若含则$S$不满足，否则去找子句进行归结，一旦出现空子句，那么$S$不满足。将互补的文字消去，留下的文字进行析取</p>
<p>归结：$C_1 ( \neg Q \vee P ), C_2 ( Q \vee R ) $可以化成$C_{12} ( P \vee R ) $</p>
<p>如果$C_1,C_2$为真，则$C_{12}$为真</p>
<p>若将$C_{12}$<strong>替换</strong>$C_1,C_2$得到$S_1$，与原来的$S_0$比较，$S_1$的不可满足性$\Rightarrow$ $S_0$的不可满足性</p>
<p>若将$C_{12}$<strong>加入</strong>$S_0$得到$S_2$，则$S_2$的不可满足性$\Leftrightarrow$ $S_0$的不可满足性</p>
<p>$C_1 = P(x) \vee Q(a),C_2 = \neg P(b) \vee R(x)$</p>
<p>令$C_2 =\neg P(b) \vee R(y)$，不同子句变量标准化</p>
<p>$L_1 = P(x),L_2=\neg P(b)$，则$\sigma = $ { $ b/x $ }</p>
<p>$C_{12} = Q(a) \vee R(y)$</p>
<p><strong>值得注意的是</strong>，当归结的$P(x)$是两个变量，如$P(x) \vee R(x)$和$\neg P(y) \vee Q(y)$或者$P(x) \vee R(x)$和$\neg P(x) \vee Q(x)$都不能进行归结。</p>
<ul>
<li><p>子句集$S$是不可满足的，当且仅当存在一个从$S$到空子句的归结过程</p>
</li>
<li><p>设$C_1$和$C_2$是两个没有公共变元的子句，$L_1$和$L_2$分别是$C_1$和$C_2$中的文字，如果$L_1$和$L_2$存在一个合一$\sigma$则：</p>
<p>$C_{12} = ( \{ C_1 , \sigma \} - \{ L_1 , \sigma \}) \cup ( \{ C_1 , \sigma \} - \{ L_1 , \sigma \}) $</p>
</li>
</ul>
<h2 id="归结反演"><a href="#归结反演" class="headerlink" title="归结反演"></a>归结反演</h2><p>用$F$证明$Q$，我们构造集合$S =  $ { $ F , \neg Q $ }，利用归结原理，将每次得到的归结式并入$S$中，若出现空语句则可停止，此时就证明了$Q$为真。</p>
<h2 id="应用归结原理求解问题"><a href="#应用归结原理求解问题" class="headerlink" title="应用归结原理求解问题"></a>应用归结原理求解问题</h2><p>用$F$求解$Q$，将$Q$用谓词公式表示，否定$Q$与answer构成析取式，加入$S$，此时$S = $ { $ F, \neg Q \vee ANSWER $ }，再通过归结，得到$ANSWER$，那么就能得出答案。</p>
<h1 id="第五讲-可信度方法和证据理论"><a href="#第五讲-可信度方法和证据理论" class="headerlink" title="第五讲 可信度方法和证据理论"></a>第五讲 可信度方法和证据理论</h1><p><a href="https://hopey233.github.io/2020/03/14/Day8不确定推理/" target="_blank" rel="noopener">部分内容</a></p>
<h2 id="5-2-可信度方法"><a href="#5-2-可信度方法" class="headerlink" title="5.2 可信度方法"></a>5.2 可信度方法</h2><p><strong>知识不确定性的表示</strong></p>
<p>$IF \ \ \ \ E  \ \ \ \  THEN \ \ \ \ H  \ \ \ \ (CF(H,E))$；$CF(H,E)$：可信度因子，反映前提条件与结论的联系强度；取值范围：$[ -1 , 1 ]$</p>
<p>若$CF(H,E) &gt; 0$，真的越确定；$&lt; 0$，假的越确定；$= 0$，证据的出现与$H$无关</p>
<p>多个单一证据的合取：</p>
<p>$E = E_1 \ AND \ E_2 \ AND … AND \ E_n$，则$CF(E) = min(CF(E_1),CF(E_2),…,CF(E_n))$</p>
<p>多个单一证据的析取：</p>
<p>$E = E_1 \ OR \ E_2 \ OR … OR \ E_n$，则$CF(E) = max(CF(E_1),CF(E_2),…,CF(E_n))$</p>
<p><strong>不确定的传递</strong></p>
<p>$CF(H) = CF(H,E) \times max(0,CF(E))$</p>
<p><strong>不确定的合成</strong></p>
<p>$CF(H,E_1) , CF(H,E_2)$</p>
<p>$CF_1(H) = CF(H,E_1) \times max(0,CF(E_1))$</p>
<p>$CF_2(H) = CF(H,E_2) \times max(0,CF(E_2))$<br>$$<br>CF_{1,2}(H) =<br>\begin{cases}<br>CF_1(H)+CF_2(H)-CF_1(H)_2CF(H) &amp; \text 若CF_1(H)  \geq 0 , CF_2(H) \geq 0  \newline<br>CF_1(H) + CF_2(H) + CF_1(H)_2CF(H) &amp; \text 若CF_1(H)  &lt; 0 , CF_2(H) &lt; 0  \newline<br>\frac{CF_1(H)+CF_2(H)}{1-min ( | CF_1(H) | , | CF_2(H) | ) }  &amp; \text CF_1(H),CF_2(H) 异号<br>\end{cases}<br>$$</p>
<h2 id="5-3-证据理论"><a href="#5-3-证据理论" class="headerlink" title="5.3 证据理论"></a>5.3 证据理论</h2><p><strong>概率分配函数</strong></p>
<p>在证据理论中，$D$的任何一个子集$A$都对应一个关于$x$的命题，称该命题为“$x$的值是在$A$中”</p>
<p>特别的$M( \varnothing  ) = 0 , \sum_{B \subseteq A} = 1$</p>
<p>概率分配函数是人工智能理论中非经典推理部分,证据理论中用到的一个函数，而概率是随机事件出现的可能性度量。</p>
<p><strong>信任函数</strong>（下限函数）</p>
<p>$Bel \ : \ 2^D \rightarrow [0,1] ($对于任何一个属于$D$的子集$A$,命它对应一个数$M \in [0,1])$且$ Bel(A) =  \sum_{B \subseteq A}^{} M(B) \ \ \ \  \forall A \subseteq D$</p>
<p>$Bel(A)$：对命题$A$为真的总的信任程度</p>
<p>$Bel(\varnothing) = M(\varnothing) = 0$</p>
<p>$Bel(D) = \sum_{B \subseteq D} M(B) = 1$</p>
<p><strong>似然函数</strong>（上限函数）</p>
<p>又称不可驳斥函数或上限函数</p>
<p>$Pl(A) = 1 - Bel(\neg A)$</p>
<p><strong>概率分配函数的正交和</strong></p>
<p>设$M_1$和$M_2$是两个概率分配函数；则其正交和$M=M_1 \oplus M_2 : M(\varnothing) = 0$</p>
<p>$M(A) = K^{-1} \sum_{x \cap y = \varnothing} M_1(x) M_2(y)$</p>
<p>$K = 1 - \sum_{x \cap y = \varnothing }M_1(x) M_2(y) = \sum_{x \cap y \neq \varnothing } M_1(x) M_2(y)$</p>
<p>如果$K \neq 0$，则正交和$M$也是一个概率分配函数</p>
<p>如果$K = 0$，则不存在正交和$M$，即没有可能存在的概率函数，称$M_1$与$M_2$矛盾</p>
<p><strong>特殊的概率分配函数</strong></p>
<p>课本上着重讲的是这种概率分配函数，上文的概率分配函数都是一般的概率分配函数</p>
<p>特殊概率分配函数具有以下性质</p>
<ul>
<li><p>为一般概率分配函数</p>
</li>
<li><p>$m(\{ s_i\}) \geq 0$</p>
</li>
<li><p>$\sum_{i=1}^{n} m (\{ s_i \}) \leq 1$</p>
</li>
<li><p>$m(\Omega) = 1 - \sum_{i=1}^{n} m (\{ s_i \})$</p>
</li>
<li><p>当子集个数等于1时，概率分配函数才有可能大于0，当子集中的元素大于1且不等于全集$\Omega$时，概率分配函数等于0</p>
</li>
<li><p>合成</p>
<ul>
<li><p>$$<br>m(\{ s_i \}) = \frac{1}{K} [m_1(\{ s_i \}) m_2(\{ s_i \}) + m_1(\{ s_i \}) m_2(\Omega) + m_1(\Omega) m_2(\{ s_i \}) ]<br>\\<br>K = m_1(\Omega) m_2(\Omega) + \sum_{i=1}^{n}[m_1(\{ s_i \}) m_2(\{ s_i \}) + m_1(\{ s_i \}) m_2(\Omega) + m_1(\Omega) m_2(\{ s_i \}) ]<br>$$</p>
</li>
<li><p>$Bel(A) = \sum_{s_i \in A} m(\{ s_i \})$</p>
</li>
<li><p>$Bel(\Omega) = \sum_{i=1}^n m(\{ s_i \}) + m(\Omega)$</p>
</li>
<li><p>$Pl(A) = m(\Omega) + Bel(A)$</p>
</li>
</ul>
</li>
</ul>
<p><strong>类概率概率函数</strong><br>$$<br>f(A) = Bel(A) + \frac{|A|}{|\Omega|} \times [Pl(A) - Bel(A)]<br>$$</p>
<ul>
<li>$f(\Omega) = 1 \ f(\varnothing)=0$</li>
<li>$Bel(A) \leq f(A) \leq Pl(A)$</li>
<li>$f(\neg A) = 1 - f(A)$</li>
</ul>
<p><strong>$H$的确定性$CER(H)$</strong></p>
<ul>
<li>MD(匹配程度)：$MD(A|E’) = \begin{cases} 1 &amp; A的元素都出现在E’ \newline 0 &amp; else \end{cases}$</li>
<li>$CER(H) = MD(A|E’) \times f(A)$</li>
<li>满足合取min，析取max</li>
</ul>
<p><strong>不确定的更新</strong><br>$$<br>IF \quad THEN \quad H = \{ h_1,h_2,…,h_n \} \quad CF = \{ c_1,c_2,…,c_n \}<br>$$</p>
<ul>
<li><p>求H的概率分配函数</p>
<ul>
<li>$m \{ \{h_1 \},\{ h_2 \},…,\}  =  (CER(E) \times c_1 ,…)$</li>
<li>$m(\Omega) = 1 - \sum_{i=1}^n CER(E) \times c_i$</li>
<li>再正交，求f，CER</li>
</ul>
</li>
<li><p>汉明距离：求两个模糊集之间的差异</p>
<ul>
<li>离散：$d(F,G) = \frac{1}{n} \times \sum_{i=1}^n |\mu_F(u_i) - \mu_G(u_i)|$</li>
<li>连续：$d(F,G) = \frac{1}{b-a} \int_a^b |\mu_F(u_i) - \mu_G(u_i)| d(u)$</li>
</ul>
</li>
<li><p>贴近度</p>
<p>$(F,G) = \frac{1}{2} \times (F \cdot G + (1 - F \bigodot  G))$</p>
<ul>
<li>$F \cdot G = \vee_U (\mu_F(u_i) \wedge \mu_G(u_i))$</li>
<li>$F \bigodot G = \wedge_U (\mu_F(u_i) \vee \mu_G(u_i))$</li>
</ul>
</li>
</ul>
<h1 id="第六讲-模糊推理方法"><a href="#第六讲-模糊推理方法" class="headerlink" title="第六讲 模糊推理方法"></a>第六讲 模糊推理方法</h1><h2 id="6-1-模糊逻辑提出"><a href="#6-1-模糊逻辑提出" class="headerlink" title="6.1 模糊逻辑提出"></a>6.1 模糊逻辑提出</h2><p>以经典集合为根基</p>
<h2 id="6-2-模糊集合和隶属函数"><a href="#6-2-模糊集合和隶属函数" class="headerlink" title="6.2 模糊集合和隶属函数"></a>6.2 模糊集合和隶属函数</h2><p>论域：所讨论的全体对象，用$U$表示</p>
<p>元素：论域中每个对象，用$a,b,c,x,y,z$表示</p>
<p>集合：相同属性聚在一起的元素集</p>
<p>经典集合：集合中元素的关系只有两种，要么属于这个集合，要么不属于这个集合</p>
<p><strong>模糊集合</strong></p>
<p>给集合中每一个元素赋予一个介于0和1之间的实数， 描述其属于一个集合的强度，该实数称为元素属于一个集合的<strong>隶属度</strong>。集合中所有元素的隶属度全体构成集合的<strong>隶属函数</strong></p>
<p>表示方法：$A =${$(x,\mu_A(x)) , x \in X$}   $\mu_A (x)$：元素$x$属于模糊集$A$的隶属度，$X$是元素$x$的论域</p>
<p>Zadeh表示法</p>
<p>1）数目有限</p>
<p>$A = \mu_A(x_1) / x_1 + \mu_A(x_2) / x_2 +…+\mu_A(x_n) / x_n  = \sum_{i=1}^{n}{\mu_A(x_i) / x_i}$</p>
<p>$A=${$\mu_A(x_1) / x_1 ,\mu_A(x_2) / x_2 ,..,\mu_A(x_n) / x_n $}</p>
<p>2) 论域连续或元素无限</p>
<p>$A = \int_{x \in U} \mu_A(x)/x$</p>
<p>序偶表示法</p>
<p>$A =${$( \mu_A(x_1) , x_1) , ( \mu_A(x_2),x_2),…,( \mu_A(x_n) , x_n)$}</p>
<p>向量表示法</p>
<p>$A=${$\mu_A(x_1),\mu_A(x_2),…,(\mu_A(x_n),x_n),$}</p>
<p><strong>隶属度</strong></p>
<p>常见的隶属函数有正态分布、三角分布、梯形分布等</p>
<p>确定方法：模糊统计法、专家经验法、二元对比排序法、基本概念扩充法</p>
<h2 id="6-3-模糊关系及其合成"><a href="#6-3-模糊关系及其合成" class="headerlink" title="6.3 模糊关系及其合成"></a>6.3 模糊关系及其合成</h2><p><strong>模糊关系的构造</strong></p>
<ul>
<li>$R_m$：$\int_{U \times V} (\mu_F(u) \wedge \mu_G(v)) \vee (1-\mu_F(u)) / (u,v)$</li>
<li>$R_c$：$\int_{U \times V} (\mu_F(u) \wedge \mu_G(v)) / (u,v)$</li>
<li>$R_g$：$\mu_F(u) \rightarrow \mu_G(v) = \begin{cases} 1 &amp; \mu_F(u) \leq \mu_G(v) \newline \mu_G(v) &amp; \mu_F(u) &gt; \mu_G(v)\end{cases}$</li>
</ul>
<p>离散模糊集，用向量乘</p>
<p>$\mu_{A \times B} (a,b) = \mu_A^T \circ  \mu_B $</p>
<p>上面的向量运算，把乘换成取小运算，加换成取大运算即可</p>
<h2 id="6-4-模糊推理与模糊决策"><a href="#6-4-模糊推理与模糊决策" class="headerlink" title="6.4 模糊推理与模糊决策"></a>6.4 模糊推理与模糊决策</h2><p>模糊推理得到的就是模糊数</p>
<p>模糊决策：由模糊推理得到的结论或者操作是一个模糊向量，转化成为确定的过程</p>
<p>最大隶属度法：取最大的隶属度所对应的元素</p>
<p>加权平均判决法：$U = \frac{ \sum_{i=1}^{n} u (v_i) v_i}{\sum_{i=1}^n u (v_i)}$</p>
<p>中位数法：隶属度的中位数所对应的元素</p>
<h2 id="6-5-模糊推理的应用"><a href="#6-5-模糊推理的应用" class="headerlink" title="6.5 模糊推理的应用"></a>6.5 模糊推理的应用</h2><p>首先对于事实进行模糊合成$R$，然后在用条件$A’$与$R$合成$B’$，然后再进行模糊决策</p>
<h1 id="第七讲-搜索求解策略"><a href="#第七讲-搜索求解策略" class="headerlink" title="第七讲 搜索求解策略"></a>第七讲 搜索求解策略</h1><h2 id="7-1-搜索的概念"><a href="#7-1-搜索的概念" class="headerlink" title="7.1 搜索的概念"></a>7.1 搜索的概念</h2><p>略</p>
<h2 id="7-2-状态空间知识表示法"><a href="#7-2-状态空间知识表示法" class="headerlink" title="7.2 状态空间知识表示法"></a>7.2 状态空间知识表示法</h2><ul>
<li><p>状态：表示系统状态、事实等叙述型知识的一组变量或数组$Q = [q_1,q_2,…,q_n]^T$</p>
</li>
<li><p>操作：表示引起状态变化的过程型知识的一组关系或函数$F =${$f_1,f_2,…,f_m$}</p>
</li>
<li><p>状态空间：利用状态变量和操作符号表示，四元组形式$(S,O,S_0,G)$</p>
</li>
<li><p>$S$：状态集合；$O$：操作算子的集合；$S_0$：包含问题的初始状态，为$S$的子集；$G$：若干具体状态或满足某些性质的路径信息描述。</p>
</li>
<li><p>求解路径：求$S_0$到$G$的路径</p>
</li>
<li><p>解：一个有限的操作算子序列$O_1O_2O_3…O_k$<br>$$<br>S_0\overset{O_1}{\rightarrow}S_1\overset{O_2}{\rightarrow}S_2\overset{O_3}{\rightarrow}…\overset{O_k}{\rightarrow}G<br>$$</p>
</li>
</ul>
<h2 id="7-3-启发式图搜索策略"><a href="#7-3-启发式图搜索策略" class="headerlink" title="7.3 启发式图搜索策略"></a>7.3 启发式图搜索策略</h2><ul>
<li>启发式信息：用来简化搜索过程有关具体问题领域的特征的信息</li>
<li>启发式图搜索策略（利用启发信息的搜索方法）的特点：重排OPEN表，选择最有希望的节点加以扩展<ul>
<li>每次更新策略函数，排序得到一个最优的策略进行更新操作</li>
<li>利用这种启发式信息的搜索过程称为启发式搜索</li>
</ul>
</li>
<li>$A$算法、$A^*$算法</li>
</ul>
<p><strong>估价函数</strong></p>
<ul>
<li>估计节点的希望程度的量度</li>
<li>定义估价函数$f(n)$：从初始节点<strong>经过</strong>$n$到达目标节点的路径最小代价估计值<ul>
<li>$f(n) = g(n)+h(n)$</li>
<li>$g(n)$：从初始节点$S_0$到节点$n$的实际代价</li>
<li>$h(n)$：从节点$n$到目标节点的最优路径的估计代价，称为启发函数</li>
<li>$h(n)$比重大：降低了搜索的工作量，但可能找不到最优解</li>
<li>$h(n)$比重小：导致工作量加大，极限情况变为盲目搜索，一般都能找到最优解</li>
</ul>
</li>
</ul>
<p><strong>$A$搜索算法</strong></p>
<ul>
<li>初始化<ul>
<li>OPEN表：待扩展节点</li>
<li>CLOSED表：已扩展节点</li>
</ul>
</li>
<li>每次寻找OPEN表中$f(n)$最小的点进行扩展，扩展完成之后加入CLOSED表</li>
</ul>
<p><strong>八数码问题</strong></p>
<p>以下是一种启发搜索的策略</p>
<p>$g(n)$：节点$n$的深度</p>
<p>$h(n)$：节点$n$与目标棋局数位不相同的个数</p>
<p><strong>$A^*$搜索算法</strong></p>
<p>如果某一问题有解，那么利用$A^*$算法一定能找到最优解而结束</p>
<ul>
<li>可采纳性：能找到解的搜索算法</li>
<li>单调性：$A^<em>$中$h(n)$*</em>单调不增**</li>
<li>信息性：如果$h_1(n) \leq h_2(n)$，称为$h_2$比$h_1$具有更多的信息性，如果$h(n)$越大，则信息性越多，所搜索状态就越少</li>
</ul>
<h1 id="第八讲-遗传算法及其应用"><a href="#第八讲-遗传算法及其应用" class="headerlink" title="第八讲 遗传算法及其应用"></a>第八讲 遗传算法及其应用</h1><p><strong>位串编码</strong></p>
<ul>
<li><p>二进制编码</p>
</li>
<li><p>Gray编码（格雷码）</p>
<ul>
<li><p>二进制串[$\beta_1\beta_2…\beta_n$]，Gray[$\gamma_1 \gamma_2 … \gamma_n$]</p>
</li>
<li><p>$$<br>\gamma_k =<br>\begin{cases}<br>\beta_1 &amp; k=1<br>\newline<br>\beta_{k-1} \bigoplus \beta_k &amp; k&gt;1<br>\end{cases}<br>$$</p>
</li>
<li><p>$$<br>\beta_k = \sum_{i=1}^k \gamma_i(mod\ 2)<br>$$</p>
</li>
</ul>
</li>
</ul>
<p><strong>适应函数和尺度变换</strong></p>
<ul>
<li>线性变换：$f’ = af+b$</li>
<li>非线性变换<ul>
<li>幂函数变换：$f’ = f^K$</li>
<li>指数变换：$f’ = e^{-af}$</li>
</ul>
</li>
</ul>
<p><strong>选择</strong></p>
<p>基本思想：适应度越高越容易被选择</p>
<p>在遗传算法中，关键就是个体的适应度和被选择个体的数目</p>
<ul>
<li><p>适应度比例法或蒙特卡洛法</p>
<ul>
<li>$$<br>p_{si} = \frac{f_i}{\sum_{i=1}^M f_i}<br>$$</li>
</ul>
</li>
<li><p>排序方法</p>
<ul>
<li><p>线性排序</p>
<ul>
<li><p>$x_1,x_2,…,x_N$</p>
</li>
<li><p>$$<br>p_i = \frac{a-bi}{M(M+1)}<br>$$</p>
</li>
</ul>
</li>
<li><p>非线性排序</p>
<ul>
<li>$$<br>p_i =<br>\begin{cases}<br>q(1-q)^{i-1} &amp; i=1,2,…,M-1<br>\newline<br>(1-q)^{M-1} &amp; i=M<br>\end{cases}<br>$$</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>交叉</strong></p>
<ul>
<li>一($n$)点交叉：随机选择一($n$)点进行组合成新个体</li>
<li>部分匹配交叉：既要有新结构体出现，又要保证合法性</li>
</ul>
<p><strong>变异</strong></p>
<ul>
<li>位点变异：变换几个点</li>
<li>逆转变异：取出一段逆序再插入</li>
<li>等等</li>
</ul>
<p><strong>遗传算法的基本步骤</strong></p>
<p><img src="/images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4.jpg" alt="alt"></p>
<p><strong>特点</strong></p>
<ul>
<li>全局优化概率算法</li>
</ul>
<h1 id="第九讲-群智能算法及其应用"><a href="#第九讲-群智能算法及其应用" class="headerlink" title="第九讲 群智能算法及其应用"></a>第九讲 群智能算法及其应用</h1><h2 id="粒子群算法-PSO"><a href="#粒子群算法-PSO" class="headerlink" title="粒子群算法(PSO)"></a>粒子群算法(PSO)</h2><p>$$<br>v_j^i(k+1)=\omega(k)v_j^i(k)+\varphi_1 rand(0,a_1)(p_j^i(k)-x_j^i(k))+\varphi_2 rand(0,a_2)(p_j^g(k)-x_j^i(k))<br>$$</p>
<ul>
<li>$P_j^i(k)$：$i$粒子走过最好的位置</li>
<li>$x_j^i(k)$：$i$粒子目前的位置</li>
<li>$p_j^g(k)$：群体走过最好的位置</li>
<li>$\varphi_1,\varphi_2$：控制个体认知分量和群体社会分量相对贡献的学习率的比重</li>
<li>$\varphi_1 &gt; 0,\varphi_2&gt;0$：PSO全模型</li>
<li>$\varphi_1 &gt; 0,\varphi_2=0$：PSO认知模型</li>
<li>$\varphi_1 = 0,\varphi_2&gt;0$：PSO社会模型</li>
<li>$\varphi_1 = 0,\varphi_2&gt;0,g \neq i$：PSO无私模型</li>
</ul>
<h2 id="蚁群算法-ACO"><a href="#蚁群算法-ACO" class="headerlink" title="蚁群算法(ACO)"></a>蚁群算法(ACO)</h2><p>信息素跟踪、信息素遗留</p>
<h1 id="BP神经网络"><a href="#BP神经网络" class="headerlink" title="BP神经网络"></a>BP神经网络</h1><p><strong>常用数学模型</strong></p>
<ul>
<li>线性激励模型</li>
<li>非线性激励模型<ul>
<li>$y = \begin{cases}<br>1 &amp; x\geq 0<br>\newline<br>0 &amp; x&lt;0<br>\end{cases}$</li>
<li>$y = \begin{cases}<br>1 &amp; x\geq 0<br>\newline<br>-1 &amp; x&lt;0<br>\end{cases}$</li>
<li>$y = \frac{1}{1+e^{- \alpha x}} \ \ \ \ \ \ \  \alpha = 1$</li>
<li>$y = \frac{e^{\alpha x} - e^{- \alpha x}}{e^{\alpha x} + e^{- \alpha x}} \ \ \ \ \ \alpha = 1$</li>
</ul>
</li>
</ul>
<p><strong>工作方式</strong></p>
<ul>
<li>神经网络结构<ul>
<li>前馈型（前向型），前面一个神经元只影响后面的神经元</li>
<li>反馈型，后面的神经元可以影响到前面的神经元</li>
</ul>
</li>
</ul>
<p><strong>BP神经网络</strong></p>
<ul>
<li><p>结构：输入层、输出层、隐层</p>
</li>
<li><p>Kolmogorov定理：给定任意$\varepsilon  &gt;0$，对于任意的$L_2$型连续函数$f:[0,1]^n \rightarrow R^m$，存在一个三层BP神经网络，其输入层有$n$个神经元，中间层有$2n+1$个神经元，输出层有$m$个神经元，它可以再任意$\varepsilon $平方误差精度内逼近$f$</p>
</li>
<li><p>目标函数：</p>
<ul>
<li>$$<br>J = \frac{1}{2}  \sum_{j=1}^{p_m}(y_j^m-d_j)^2<br>$$</li>
</ul>
</li>
<li><p>约束条件</p>
<ul>
<li><p>$$<br>u_i^k =  \sum_{j} w_{ij}^{k-1}y_j^{k-1} \ \ \ i=1,2,…,p_k<br>$$</p>
</li>
<li><p>$$<br>y_i^k = f_k(u_i^k) \ \ \ k = 1,2,…,m<br>$$</p>
</li>
</ul>
</li>
<li><p>连接权值的修正量</p>
<ul>
<li>$$<br>\Delta w_{ij}^{k-1} = - \varepsilon \frac{\partial J}{\partial w_{ij}^{k-1}} \ \ \ j=1,2,…,p_{k-1}<br>$$</li>
</ul>
</li>
<li><p>学习算法</p>
<ul>
<li>正向传播：输入信息由输入层传至隐层，最终在输出层输出</li>
<li>反向传播：修改各层神经元的权值，使误差信号最小</li>
</ul>
</li>
<li><p>BP算法设计</p>
<ul>
<li>隐层数及隐层神经元的确定</li>
<li>初始权值设置，一般以一个均值为$0$的随机分布设置网络的初始权值</li>
<li>训练数据预处理：线性的特征比例变换，将所有的特征变换到[0,1]或者[-1,1]区间内，使得在每个训练集上，每个特征的均值为0，并且具有相同的方差</li>
<li>后处理过程</li>
</ul>
</li>
<li><p>BP算法的实现</p>
<ul>
<li><p>初始化：对于所有连接权和阈值赋值以随机任意小值$w_{ij}^k(t),\theta_i^k(t)(k=1,..,m;i=1,..,p_k;t=0)$</p>
</li>
<li><p>取出一组样本，输入</p>
</li>
<li><p>计算各层节点的输出$y_i^k$</p>
</li>
<li><p>计算误差：$e_i = y_i - y_i^m$</p>
</li>
<li><p>计算反向传播的误差</p>
<ul>
<li><p>$$<br>\Delta w_{ij} = -\alpha d_i^ky_j^{k-1}<br>$$</p>
</li>
<li><p>$$<br>d_i^m = y_i^m(1-y_i^m)(y_i^m-y_i)<br>$$</p>
</li>
<li><p>$$<br>d_i^k = y_i^k(1-y_i^k)  \sum_{l=1}^{p_{k+1}}w_{li}^{k+1}d_l^{k+1}<br>$$</p>
</li>
</ul>
</li>
<li><p>重复上述过程，直到所有的误差满足条件</p>
</li>
</ul>
</li>
<li><p>优点</p>
<ul>
<li>很好的逼近特性</li>
<li>具有较强的泛化能力</li>
<li>具有较好的容错性</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>具有较好的容错性</li>
<li>局部极值</li>
<li>难以确定隐层和隐层结点的数目</li>
</ul>
</li>
<li><p>应用</p>
<ul>
<li>模式识别</li>
<li>软测量</li>
</ul>
</li>
</ul>
<h1 id="Hopfield神经网络"><a href="#Hopfield神经网络" class="headerlink" title="Hopfield神经网络"></a>Hopfield神经网络</h1><h2 id="离散型Hopfield"><a href="#离散型Hopfield" class="headerlink" title="离散型Hopfield"></a>离散型Hopfield</h2><ul>
<li>输入输出关系<ul>
<li>$x(k+1)=f(W_x(k) - \theta) , \forall i$<ul>
<li>$X=[x_1,x_2,…,x_n]^T$</li>
<li>$\Theta=[\theta_1,\theta_2,..,\theta_n]^T$</li>
<li>$W=[w_{ij}] \ \ w_{ii}=0$</li>
<li>$F(s) = [f(s_1),f(s_2),…,f(s_n)]^T$</li>
</ul>
</li>
<li>$x_i(k+1) = f(\sum_{j=1}^n w_{ij}x_j(k) - \theta_i)$</li>
<li>$f(x) = \begin{cases}<br>1 &amp; x\geq 0<br>\newline<br>-1 &amp; x&lt;0<br>\end{cases}$</li>
<li>$ f(x) = \begin{cases}<br>1 &amp; x\geq 0<br>\newline<br>0 &amp; x&lt;0<br>\end{cases}$</li>
</ul>
</li>
<li>工作方式<ul>
<li>异步（串行）方式<ul>
<li>$x_i(k+1) = f(\sum_{j=1}^n w_{ij}x_j(k) - \theta_i)$</li>
<li>$x_j(k+1) = x_j(k) \ \ \ j \neq i$</li>
</ul>
</li>
<li>同步（并行）方式<ul>
<li>$x(k+1)=f(W_x(k) - \theta) , \forall i$</li>
<li>$x_i(k+1) = f(\sum_{j=1}^n w_{ij}x_j(k) - \theta_i) \ \ \ \forall i$</li>
</ul>
</li>
</ul>
</li>
<li>通过给定的算法和由记忆样本的部分信息组成的初态，通过异步或者同步的方式（联想记忆）达到一个稳态（记忆样本）</li>
<li>稳态：从某一刻开始，网络中的神经元状态不再发生改变</li>
<li>稳定性定理<ul>
<li>串行稳定性$W$：对称阵</li>
<li>并行稳定性$W$：非负定对称阵</li>
</ul>
</li>
</ul>
<h2 id="连续性Hopfield"><a href="#连续性Hopfield" class="headerlink" title="连续性Hopfield"></a>连续性Hopfield</h2><ul>
<li><p>能量函数</p>
<ul>
<li>$$<br>E = - \frac{1}{2}  \sum_{i=1}^{n}  \sum_{j=1}^{n} w_{ij}v_iv_j -  \sum_{i=1}^{n}v_iI_i+  \sum_{i=1}^{n} \frac{1}{R’}  \int_{0}^{v_i}f^{-1}(v)dv<br>$$</li>
</ul>
</li>
<li><p>对于连续型Hopfield神经网络，若$f^{-1}(x)$为单调递增的连续函数，$C_i &gt; 0 , w_{ij}=w_{ji}$，则$\frac{dE}{dt} \leq 0$；当且仅当$\frac{dv_i}{dt} = 0 , i \in [1,n]$时，$\frac{dE}{dt} = 0$</p>
</li>
</ul>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>thanks!</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/Wechat.png" alt="Hope_Y 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/Alipay.jpg" alt="Hope_Y 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/02/26/算法/" rel="next" title="算法">
                <i class="fa fa-chevron-left"></i> 算法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/02/26/工程经济学/" rel="prev" title="工程经济学">
                工程经济学 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/00.jpg" alt="Hope_Y">
            
              <p class="site-author-name" itemprop="name">Hope_Y</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hopey233" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:1954105421@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#第一讲-人工智能概述"><span class="nav-text">第一讲 人工智能概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-简介"><span class="nav-text">1.1 简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-人工智能的概念"><span class="nav-text">1.2 人工智能的概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-人工智能的发展简史"><span class="nav-text">1.3 人工智能的发展简史</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-人工智能研究的基本内容不同学派"><span class="nav-text">1.4 人工智能研究的基本内容不同学派</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第二讲-一阶谓词逻辑知识表示法"><span class="nav-text">第二讲 一阶谓词逻辑知识表示法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-命题逻辑"><span class="nav-text">2.1 命题逻辑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-谓词逻辑"><span class="nav-text">2.2 谓词逻辑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-一阶谓词逻辑知识表示法"><span class="nav-text">2.3 一阶谓词逻辑知识表示法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第三讲-产生式表示法和框架表示法"><span class="nav-text">第三讲 产生式表示法和框架表示法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-产生式表示法"><span class="nav-text">3.1 产生式表示法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-语义网络表示法"><span class="nav-text">3.2 语义网络表示法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-框架表示法"><span class="nav-text">3.3 框架表示法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第四讲-基于谓词逻辑的推理方法"><span class="nav-text">第四讲 基于谓词逻辑的推理方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#归结演绎推理"><span class="nav-text">归结演绎推理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#鲁宾逊归结原理"><span class="nav-text">鲁宾逊归结原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#归结反演"><span class="nav-text">归结反演</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#应用归结原理求解问题"><span class="nav-text">应用归结原理求解问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第五讲-可信度方法和证据理论"><span class="nav-text">第五讲 可信度方法和证据理论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-可信度方法"><span class="nav-text">5.2 可信度方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-证据理论"><span class="nav-text">5.3 证据理论</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第六讲-模糊推理方法"><span class="nav-text">第六讲 模糊推理方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-模糊逻辑提出"><span class="nav-text">6.1 模糊逻辑提出</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-模糊集合和隶属函数"><span class="nav-text">6.2 模糊集合和隶属函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-模糊关系及其合成"><span class="nav-text">6.3 模糊关系及其合成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-模糊推理与模糊决策"><span class="nav-text">6.4 模糊推理与模糊决策</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-5-模糊推理的应用"><span class="nav-text">6.5 模糊推理的应用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第七讲-搜索求解策略"><span class="nav-text">第七讲 搜索求解策略</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-搜索的概念"><span class="nav-text">7.1 搜索的概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-状态空间知识表示法"><span class="nav-text">7.2 状态空间知识表示法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-3-启发式图搜索策略"><span class="nav-text">7.3 启发式图搜索策略</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第八讲-遗传算法及其应用"><span class="nav-text">第八讲 遗传算法及其应用</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第九讲-群智能算法及其应用"><span class="nav-text">第九讲 群智能算法及其应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#粒子群算法-PSO"><span class="nav-text">粒子群算法(PSO)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#蚁群算法-ACO"><span class="nav-text">蚁群算法(ACO)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BP神经网络"><span class="nav-text">BP神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hopfield神经网络"><span class="nav-text">Hopfield神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#离散型Hopfield"><span class="nav-text">离散型Hopfield</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#连续性Hopfield"><span class="nav-text">连续性Hopfield</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hope_Y</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://github.com/hopey233/hopey233.github.io">Hope_Y</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">QAQ-
  I can do all things
  </div>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">
</span>


  <script src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js"></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '5PmmFV0NaDBc4yxtJHhmo02r-gzGzoHsz',
        appKey: 'vmJwEjA28DWtqGUMfE08B8Cr',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
